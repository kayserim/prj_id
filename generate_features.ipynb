{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kayserim/prj_id/blob/main/generate_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "524YKhXpIIPi",
        "outputId": "e80d3d04-cb9c-4bf2-ee02-9480384caa45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/cse6250_proj\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/MyDrive/cse6250_proj' "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime,timedelta\n",
        "from collections import defaultdict, Counter\n",
        "import dask\n",
        "import math\n",
        "import dask.dataframe as dd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "HOURS_IN_A_DAY = 24\n",
        "HOURS_LIMIT = 48\n",
        "\n",
        "path = './data/all/'\n",
        "#path = './data/demo/'\n",
        "\n",
        "def fill_missing_values(current_value, map_value, default_value):\n",
        "  if pd.notna(current_value):\n",
        "    return current_value\n",
        "  if pd.notna(map_value):\n",
        "    return map_value\n",
        "  return default_value"
      ],
      "metadata": {
        "id": "j8q3Sm9xIYvr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regress_features(df: pd.DataFrame, \n",
        "                    x_val: str,\n",
        "                    feature_list: list) -> pd.DataFrame:\n",
        "  '''This function regresses a features against a common predictor.\n",
        "\n",
        "  Args:\n",
        "    data: Pandas dataframe to regress\n",
        "    x_val: String value of X value to use as predictor.\n",
        "    feature_list: The features to regress.\n",
        "\n",
        "  Returns:\n",
        "    feature_dict: Dictionary of features storing feature mapped to a tuple.\n",
        "  '''\n",
        "  icu_map = dict()\n",
        "  feature_dict = dict()\n",
        "  data = df.copy()\n",
        "  icu_id_list = data['ICUSTAY_ID'].unique()\n",
        "  for icu_id in icu_id_list:\n",
        "    data_temp = data[data['ICUSTAY_ID'] == icu_id]\n",
        "    temp_list = []\n",
        "    for f in feature_list:\n",
        "      x = np.array(data_temp[x_val]).reshape(-1, 1)\n",
        "      y = np.array(data_temp[f])\n",
        "      reg = LinearRegression().fit(x, y)\n",
        "      feature_dict[icu_id, f] = (reg.coef_.item(), reg.intercept_)\n",
        "\n",
        "  feature_df = pd.DataFrame.from_dict(feature_dict, orient='index').reset_index()\n",
        "  feature_df[['ICUSTAY_ID', 'FEATURE']]= pd.DataFrame(feature_df['index'].to_list())\n",
        "  feature_df = feature_df.rename(columns = {0:'RATE', 1:'BIAS'}).drop(columns = ['index'])\n",
        "\n",
        "  return feature_df\n",
        "    "
      ],
      "metadata": {
        "id": "tJPYLPr29wjw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def diagnoses_map(col:any) -> str:\n",
        "  '''A mapping of ICD code to diagnosis.\n",
        "\n",
        "  Args: \n",
        "    col = the column to input, any value\n",
        "  Returns:\n",
        "    result = string corresponding to the ICD9 code\n",
        "  '''\n",
        "  if str(col).startswith(('E', 'V')):\n",
        "    result = 'DIAG_EXTERNAL'\n",
        "  elif math.isnan(float(col)):\n",
        "    result = 'NONE'\n",
        "  else:\n",
        "    val = int(col)\n",
        "\n",
        "    if val < 140:\n",
        "      result = 'DIAG_INFECTIOUS'\n",
        "    elif val < 240:\n",
        "      result = 'DIAG_NEOPLASMS'\n",
        "    elif val < 280:\n",
        "      result = 'DIAG_IMMUNITY'\n",
        "    elif val < 290:\n",
        "      result = 'DIAG_BLOOD'\n",
        "    elif val < 320:\n",
        "      result = 'DIAG_MENTAL'\n",
        "    elif val < 390:\n",
        "      result = 'DIAG_NERVOUS_SYS'\n",
        "    elif val < 460:\n",
        "      result = 'DIAG_CIRCULATORY_SYS'\n",
        "    elif val < 520:\n",
        "      result = 'DIAG_RESP_SYS'\n",
        "    elif val < 580:\n",
        "      result = 'DIAG_DIGESTIVE_SYS'\n",
        "    elif val < 630:\n",
        "      result = 'DIAG_GENITOURINARY'\n",
        "    elif val < 680:\n",
        "      result = 'DIAG_PREGNANCY'\n",
        "    elif val < 710:\n",
        "      result = 'DIAG_SKIN'\n",
        "    elif val < 740:\n",
        "      result = 'DIAG_MUSC'\n",
        "    elif val < 760:\n",
        "      result = 'DIAG_CONGENITAL'\n",
        "    elif val < 780:\n",
        "      result = 'DIAG_PERINATAL'\n",
        "    elif val < 800:\n",
        "      result = 'DIAG_ILL_DEFINED'\n",
        "    elif val < 1000:\n",
        "      result = 'DIAG_INJURY'\n",
        "    else:\n",
        "      result = 'OTHER'\n",
        "  return result"
      ],
      "metadata": {
        "id": "1Jg_p1GiM3E5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_diag_dataset(diagnoses_icd: pd.DataFrame) -> pd.DataFrame:\n",
        "  '''This function takes in the diagnoses data and returns columns that can be\n",
        "  input into the model.\n",
        "\n",
        "  Params:\n",
        "    diagnoses_icd: the diagnosis dataframe\n",
        "  Returns:\n",
        "    df_diag: dignosis vals to columns\n",
        "  '''\n",
        "  diagnoses_icd['GROUP'] = diagnoses_icd[\"ICD9_CODE\"].map(diagnoses_map)\n",
        "  df_diag = diagnoses_icd[(diagnoses_icd['GROUP'] != 'OTHER') & (diagnoses_icd['GROUP'] != 'NONE')]\n",
        "  df_diag['value'] = 1\n",
        "  df_diag = df_diag.pivot_table(values = 'value', index = ['SUBJECT_ID', 'HADM_ID'], columns = 'GROUP').reset_index()\n",
        "  df_diag.fillna(0, inplace = True)\n",
        "  return df_diag"
      ],
      "metadata": {
        "id": "xL0DX44QRqhd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_demographics_dataset(admissions, patients):\n",
        "  demographics_merged = admissions.merge(patients,\n",
        "                                       on = \"SUBJECT_ID\")[[\n",
        "                                           \"SUBJECT_ID\",\n",
        "                                           \"DOB\",\n",
        "                                           \"ADMITTIME\",\n",
        "                                           \"ETHNICITY\",\n",
        "                                           \"GENDER\"]]\n",
        "\n",
        "  demographics_merged[\"ADMITTIME\"] = pd.to_datetime(demographics_merged[\"ADMITTIME\"]).dt.date\n",
        "  demographics_merged[\"DOB\"] = pd.to_datetime(demographics_merged[\"DOB\"]).dt.date\n",
        "  demographics_merged['AGE'] = demographics_merged.apply(lambda e: (e['ADMITTIME'] - e['DOB']).days/365, axis=1)\n",
        "\n",
        "  demographics = demographics_merged.groupby([\"SUBJECT_ID\",\n",
        "                                                    \"DOB\",\n",
        "                                                    \"ADMITTIME\",\n",
        "                                                    \"ETHNICITY\",\n",
        "                                                    \"GENDER\"])[\"AGE\"].min().reset_index()\n",
        "\n",
        "  demographics[\"value\"] = 1\n",
        "  demographics[\"GENDER\"] = np.where(demographics[\"GENDER\"] == \"M\", 1, 0)\n",
        "  demographics = demographics.pivot_table(values = \"value\",\n",
        "                                          index = ['SUBJECT_ID', 'AGE', 'GENDER'],\n",
        "                                          columns = [\"ETHNICITY\"]).reset_index()      \n",
        "\n",
        "  demographics.fillna(0, inplace = True)        \n",
        "\n",
        "  return demographics"
      ],
      "metadata": {
        "id": "os-9HyOhmLQd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Datasets"
      ],
      "metadata": {
        "id": "3UtoVpd11lrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = 'CHARTEVENTS_LITE.csv'\n",
        "chartevents = dd.read_csv(path+file)\n",
        "#chartevents['CHARTTIME'] = pd.to_datetime(chartevents['CHARTTIME'])"
      ],
      "metadata": {
        "id": "ky0m7pdHIjLO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = 'ICUSTAYS_LITE.csv'\n",
        "icustays = pd.read_csv(path+file)\n",
        "icustays['OUTTIME'] = pd.to_datetime(icustays['OUTTIME'])"
      ],
      "metadata": {
        "id": "zpp_f9IhI10J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = 'DIAGNOSES_ICD.csv'\n",
        "diagnoses_icd = pd.read_csv(path+file)"
      ],
      "metadata": {
        "id": "ksgG_zNuznuV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = 'D_ICD_DIAGNOSES.csv'\n",
        "d_icd_diagnoses = pd.read_csv(path+file)"
      ],
      "metadata": {
        "id": "8HbGyWKdzzOO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = 'ADMISSIONS.csv'\n",
        "admissions = pd.read_csv(path+file)"
      ],
      "metadata": {
        "id": "hqHIYI1Te9xw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = 'PATIENTS.csv'\n",
        "patients = pd.read_csv(path+file)"
      ],
      "metadata": {
        "id": "6FNL3Vzufzjk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process Data"
      ],
      "metadata": {
        "id": "sI7xYNeyVTUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diagnosis = create_diag_dataset(diagnoses_icd)"
      ],
      "metadata": {
        "id": "xV_giWIvVWaG",
        "outputId": "3b0b88be-1e9d-4198-fba9-0b0e277718b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-eb8b718261b0>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_diag['value'] = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "demographics = create_demographics_dataset(admissions, patients)"
      ],
      "metadata": {
        "id": "uc0a1GgpXvOk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chartevents_merged = chartevents.merge(dd.from_pandas(icustays, npartitions=1), on='ICUSTAY_ID', how='inner').compute().dropna(subset=['ICUSTAY_ID'])\n",
        "chartevents_merged['CHARTTIME'] = pd.to_datetime(chartevents_merged['CHARTTIME'])"
      ],
      "metadata": {
        "id": "ojo9OfGTJbup"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# only one HADMID per user\n",
        "max(chartevents_merged.groupby(\"ICUSTAY_ID\")[\"HADM_ID\"].nunique())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YArSDEhn9To",
        "outputId": "4abf2039-93a3-4556-fba7-8ba01eaf3026"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_df=pd.DataFrame([])\n",
        "base_df['ICUSTAY_ID'] = icustays.ICUSTAY_ID\n",
        "base_df['SUBJECT_ID'] = icustays.SUBJECT_ID\n",
        "base_df['HADM_ID'] = icustays.HADM_ID # if we want to add hadm id\n",
        "base_df['HOUR'] = 1\n",
        "base_df_extended = pd.concat([pd.DataFrame({'ICUSTAY_ID': row.ICUSTAY_ID,\n",
        "                                            'HADM_ID' : row.HADM_ID,\n",
        "                                            'SUBJECT_ID' : row.SUBJECT_ID,\n",
        "                                            'HOUR': pd.RangeIndex(1,HOURS_LIMIT+1)}) for i, row in base_df.iterrows()], ignore_index=True)\n",
        "\n",
        "data_all = base_df_extended.copy()\n",
        "list_of_features = [\n",
        "    {'ID':223761, 'DESC':'HRLY_TEMP', 'CESTAT':True}, \n",
        "    {'ID':220050, 'DESC':'HRLY_BPRS_SYS', 'CESTAT':True}, \n",
        "    {'ID':220051, 'DESC':'HRLY_BPRS_DIA', 'CESTAT':True}, \n",
        "    {'ID':220045, 'DESC':'HRLY_HRT_RATE', 'CESTAT':True}, \n",
        "    {'ID':225664, 'DESC':'HRLY_GLCS', 'CESTAT':True}, \n",
        "    {'ID':220210, 'DESC':'HRLY_RSP_RATE', 'CESTAT':True}, \n",
        "    {'ID':223830, 'DESC':'HRLY_PH', 'CESTAT':True}]#later will use HRLY_ prefix when giving datasets to models\n",
        "# SKIPPING FOLLOWING:\n",
        "# TOO FEW MEASUREMENTS FOR: capillary refill rate, Cholesterol\n",
        "# TOO MANY POSSIBILITIES: URINE\n",
        "# OPEN ENDED TEXT DATA: Glascow coma eye, Verbal Response, motor response parameters   \n",
        "    \n",
        "for elem in list_of_features:\n",
        "  ID = elem['ID']\n",
        "  DESC = elem['DESC']\n",
        "  data = chartevents_merged.loc[chartevents_merged.ITEMID==ID]\n",
        "  data['HOUR'] = np.ceil((data['OUTTIME']-data['CHARTTIME'])/pd.Timedelta(1,'h'))\n",
        "  data['HOUR'] = data.HOUR.astype('int64')\n",
        "  data = data.loc[data.HOUR <= HOURS_LIMIT]#last 48 hours only\n",
        "  #SHOWS THAT MEASUREMENTS ARE NOT UNIFORMLY TAKEN (SO MISSING DATA EXPECTED)\n",
        "  #data.HOUR.plot.hist(bins=HOURS_LIMIT)\n",
        "  #WHEN CNT>1 SHOWS THAT MULTIPLE DATA POINTS EXISTS PER HOUR\n",
        "  #print(data.groupby(['ICUSTAY_ID', 'HOUR']).size().reset_index(name='CNT').sort_values(by='CNT').groupby(['ICUSTAY_ID']).last().reset_index().head(20))\n",
        "\n",
        "  #TODO AVERAGING WON'T WORK FOR CATEGORICAL DATA\n",
        "  data_avg = data.groupby(['ICUSTAY_ID', 'HOUR', 'HADM_ID'])['VALUENUM'].mean().reset_index()\n",
        "  ALL_AVG = data_avg.VALUENUM.mean() #tobe used if no data exists for the icu stay\n",
        "  icustay_most_recent_data = data_avg.sort_values(by='HOUR').groupby('ICUSTAY_ID').first().reset_index()[['ICUSTAY_ID', 'VALUENUM']] \n",
        "  icustay_most_recent_data_map = defaultdict(lambda:np.NaN, dict(zip(icustay_most_recent_data.ICUSTAY_ID, icustay_most_recent_data.VALUENUM)))#tobe used for missing values i.e. use most recent measurement\n",
        "\n",
        "  #filling missing values\n",
        "  data_extended = base_df_extended.merge(data_avg, on=['ICUSTAY_ID', 'HOUR'], how='left')\n",
        "  data_extended['VALUENUM'] = data_extended.apply(lambda row: fill_missing_values(row['VALUENUM'], icustay_most_recent_data_map[row['ICUSTAY_ID']], ALL_AVG), axis=1)\n",
        "  data_all[DESC] = data_extended['VALUENUM'] #assuming order is maintained \n",
        "\n",
        "regress_ft_list = [feature['DESC'] for feature in list_of_features if feature['CESTAT']]\n",
        "regressed_features = regress_features(data_all, 'HOUR', regress_ft_list)\n",
        "\n",
        "regression_df = pd.DataFrame()\n",
        "for ft in regress_ft_list:\n",
        "  data_temp = regressed_features[regressed_features['FEATURE'] == ft][['ICUSTAY_ID', 'RATE', 'BIAS']]\n",
        "  data_temp = data_temp.rename(columns = {'RATE': 'CESTAT_'+ft+'_RATE', 'BIAS': 'CESTAT_'+ft+'_BIAS'})#later will use CESTAT prefix when giving datasets to models\n",
        "  regression_df = data_temp if regression_df.empty else regression_df.merge(data_temp, on = ['ICUSTAY_ID'])\n",
        "  "
      ],
      "metadata": {
        "id": "CksqWCkzHMAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = data_all.pivot(index='ICUSTAY_ID', columns=['HOUR']).reset_index()\n",
        "reordered_columns = [(desc,hour) for hour in range(1,1+HOURS_LIMIT) for desc in [feature['DESC'] for feature in list_of_features]]\n",
        "df_final = df_final.reindex([('ICUSTAY_ID', '')]+reordered_columns, axis=1)\n",
        "df_final.columns = [str(col[0])+str(col[1]) for col in df_final.columns.values] #converting tuples to string for better display as well as making ICUSTAY_ID column name simpler\n",
        "df_final = df_final.merge(data_all[[\"ICUSTAY_ID\", \"HADM_ID\", \"SUBJECT_ID\"]].drop_duplicates(), on=\"ICUSTAY_ID\")\n",
        "df_final = df_final.merge(regression_df, on='ICUSTAY_ID', how='inner')\n",
        "print(df_final.shape)\n",
        "df_final = df_final.merge(demographics, on='SUBJECT_ID', how='inner')\n",
        "print(df_final.shape)\n",
        "df_final = df_final.merge(diagnosis, on='HADM_ID', how='inner')\n",
        "print(df_final.shape)\n",
        "df_final = df_final.merge(icustays[['ICUSTAY_ID', 'POSITIVE']], on='ICUSTAY_ID', how='inner')\n",
        "#df_final.head(5)"
      ],
      "metadata": {
        "id": "p5kAlRgrQ-Kp",
        "outputId": "92a62b3c-5293-425a-dee1-172a04c851b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(49128, 353)\n",
            "(101763, 396)\n",
            "(83873, 413)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalization"
      ],
      "metadata": {
        "id": "dgMUXQ9rzN3W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Min Max Scaler\n",
        "scaler = MinMaxScaler()\n",
        "df_final = df_final.drop(['HADM_ID', 'SUBJECT_ID_x','SUBJECT_ID_y'], axis=1)\n",
        "df_final = pd.DataFrame(scaler.fit_transform(df_final.drop([\"ICUSTAY_ID\"], axis = 1)),\n",
        "                        columns = df_final.drop([\"ICUSTAY_ID\"], axis = 1).columns)"
      ],
      "metadata": {
        "id": "bQCQoooGyTZd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Final Datasets"
      ],
      "metadata": {
        "id": "4f2Jtq3UzQQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X=df_final.iloc[:,:-1]\n",
        "y=df_final.iloc[:,-1:]\n",
        "\n",
        "# Smote Sampling\n",
        "sm = SMOTE(random_state = 42)\n",
        "X_res, y_res = sm.fit_resample(X, y)\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X_res, y_res, test_size=0.2, random_state=0, stratify=y_res)\n",
        "X_test, X_validation, y_test, y_validation = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0, stratify=y_temp)\n"
      ],
      "metadata": {
        "id": "4M1h4i1rQkkA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([X_train, y_train], axis=1).to_csv('./data/all/XY_train_LITE.csv', index=False)\n",
        "pd.concat([X_test, y_test], axis=1).to_csv('./data/all/XY_test_LITE.csv', index=False)\n",
        "pd.concat([X_validation, y_validation], axis=1).to_csv('./data/all/XY_validation_LITE.csv', index=False)"
      ],
      "metadata": {
        "id": "e1Ex2bkgvFgd"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}