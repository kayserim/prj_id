{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOfkoO2d9UtHHVig/FOf2/3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kayserim/prj_id/blob/main/generate_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "524YKhXpIIPi"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "%cd '/content/drive/MyDrive/cse6250_proj' "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime,timedelta\n",
        "from collections import defaultdict\n",
        "import dask\n",
        "import dask.dataframe as dd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "HOURS_IN_A_DAY = 24\n",
        "HOURS_LIMIT = 48\n",
        "\n",
        "path = './data/all/'\n",
        "#path = './data/demo/'\n",
        "\n",
        "def fill_missing_values(current_value, map_value, default_value):\n",
        "  if pd.notna(current_value):\n",
        "    return current_value\n",
        "  if pd.notna(map_value):\n",
        "    return map_value\n",
        "  return default_value"
      ],
      "metadata": {
        "id": "j8q3Sm9xIYvr"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = 'CHARTEVENTS_LITE.csv'\n",
        "chartevents = pd.read_csv(path+file)\n",
        "chartevents['CHARTTIME'] = pd.to_datetime(chartevents['CHARTTIME'])"
      ],
      "metadata": {
        "id": "ky0m7pdHIjLO"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = 'ICUSTAYS_LITE.csv'\n",
        "icustays = pd.read_csv(path+file)\n",
        "icustays['OUTTIME'] = pd.to_datetime(icustays['OUTTIME'])"
      ],
      "metadata": {
        "id": "zpp_f9IhI10J"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chartevents_merged = chartevents.merge(icustays, on='ICUSTAY_ID', how='inner').dropna(subset=['ICUSTAY_ID'])"
      ],
      "metadata": {
        "id": "ojo9OfGTJbup"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_df=pd.DataFrame([])\n",
        "base_df['ICUSTAY_ID'] = icustays.ICUSTAY_ID\n",
        "base_df['HOUR'] = 1\n",
        "base_df_extended = pd.concat([pd.DataFrame({'ICUSTAY_ID': row.ICUSTAY_ID, 'HOUR': pd.RangeIndex(1,HOURS_LIMIT+1)}) for i, row in base_df.iterrows()], ignore_index=True)\n",
        "\n",
        "data_all = base_df_extended.copy()\n",
        "list_of_features = [{'ID':223761, 'DESC':'TEMP'}, {'ID':220050, 'DESC':'BPRS_SYS'}]\n",
        "for elem in list_of_features:\n",
        "  ID = elem['ID']\n",
        "  DESC = elem['DESC']\n",
        "  data = chartevents_merged.loc[chartevents_merged.ITEMID==ID]\n",
        "  data['HOUR'] = np.ceil((data['OUTTIME']-data['CHARTTIME'])/pd.Timedelta(1,'h'))\n",
        "  data['HOUR'] = data.HOUR.astype('int64')\n",
        "  data = data.loc[data.HOUR <= HOURS_LIMIT]#last 48 hours only\n",
        "  #SHOWS THAT MEASUREMENTS ARE NOT UNIFORMLY TAKEN (SO MISSING DATA EXPECTED)\n",
        "  #data.HOUR.plot.hist(bins=HOURS_LIMIT)\n",
        "  #WHEN CNT>1 SHOWS THAT MULTIPLE DATA POINTS EXISTS PER HOUR\n",
        "  #print(data.groupby(['ICUSTAY_ID', 'HOUR']).size().reset_index(name='CNT').sort_values(by='CNT').groupby(['ICUSTAY_ID']).last().reset_index().head(20))\n",
        "\n",
        "  #TODO AVERAGING WON'T WORK FOR CATEGORICAL DATA\n",
        "  data_avg = data.groupby(['ICUSTAY_ID', 'HOUR'])['VALUENUM'].mean().reset_index()\n",
        "  ALL_AVG = data_avg.VALUENUM.mean() #tobe used if no data exists for the icu stay\n",
        "  icustay_most_recent_data = data_avg.sort_values(by='HOUR').groupby('ICUSTAY_ID').first().reset_index()[['ICUSTAY_ID', 'VALUENUM']] \n",
        "  icustay_most_recent_data_map = defaultdict(lambda:np.NaN, dict(zip(icustay_most_recent_data.ICUSTAY_ID, icustay_most_recent_data.VALUENUM)))#tobe used for missing values i.e. use most recent measurement\n",
        "\n",
        "  #filling missing values\n",
        "  data_extended = base_df_extended.merge(data_avg, on=['ICUSTAY_ID', 'HOUR'], how='left')\n",
        "  data_extended['VALUENUM'] = data_extended.apply(lambda row: fill_missing_values(row['VALUENUM'], icustay_most_recent_data_map[row['ICUSTAY_ID']], ALL_AVG), axis=1)\n",
        "  data_all[DESC] = data_extended['VALUENUM'] #assuming order is maintained "
      ],
      "metadata": {
        "id": "CksqWCkzHMAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = data_all.pivot(index='ICUSTAY_ID', columns=['HOUR']).reset_index()\n",
        "reordered_columns = [(desc,hour) for hour in range(1,1+HOURS_LIMIT) for desc in [feature['DESC'] for feature in list_of_features]]\n",
        "df_final = df_final.reindex([('ICUSTAY_ID', '')]+reordered_columns, axis=1)\n",
        "df_final.columns = [str(col[0])+str(col[1]) for col in df_final.columns.values] #converting tuples to string for better display as well as making ICUSTAY_ID column name simpler\n",
        "df_final = df_final.merge(icustays[['ICUSTAY_ID', 'POSITIVE']], on='ICUSTAY_ID', how='inner')\n",
        "#df_final.head(5)"
      ],
      "metadata": {
        "id": "p5kAlRgrQ-Kp"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df_final.iloc[:,:-1]\n",
        "y=df_final.iloc[:,-1:]\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
        "X_test, X_validation, y_test, y_validation = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0, stratify=y_temp)\n"
      ],
      "metadata": {
        "id": "4M1h4i1rQkkA"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([X_train, y_train], axis=1).to_csv('./data/all/XY_train_LITE.csv', index=False)\n",
        "pd.concat([X_test, y_test], axis=1).to_csv('./data/all/XY_test_LITE.csv', index=False)\n",
        "pd.concat([X_validation, y_validation], axis=1).to_csv('./data/all/XY_validation_LITE.csv', index=False)"
      ],
      "metadata": {
        "id": "e1Ex2bkgvFgd"
      },
      "execution_count": 75,
      "outputs": []
    }
  ]
}