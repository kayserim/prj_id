{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kayserim/prj_id/blob/main/generate_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "524YKhXpIIPi",
        "outputId": "46c5df1f-213b-4056-bbac-5c288a1d5c7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/cse6250_proj\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/MyDrive/cse6250_proj' "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime,timedelta\n",
        "from collections import defaultdict\n",
        "import dask\n",
        "import math\n",
        "import dask.dataframe as dd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "HOURS_IN_A_DAY = 24\n",
        "HOURS_LIMIT = 48\n",
        "\n",
        "path = './data/all/'\n",
        "#path = './data/demo/'\n",
        "\n",
        "def fill_missing_values(current_value, map_value, default_value):\n",
        "  if pd.notna(current_value):\n",
        "    return current_value\n",
        "  if pd.notna(map_value):\n",
        "    return map_value\n",
        "  return default_value"
      ],
      "metadata": {
        "id": "j8q3Sm9xIYvr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regress_features(df: pd.DataFrame, \n",
        "                    x_val: str,\n",
        "                    feature_list: list) -> pd.DataFrame:\n",
        "  '''This function regresses a features against a common predictor.\n",
        "\n",
        "  Args:\n",
        "    data: Pandas dataframe to regress\n",
        "    x_val: String value of X value to use as predictor.\n",
        "    feature_list: The features to regress.\n",
        "\n",
        "  Returns:\n",
        "    feature_dict: Dictionary of features storing feature mapped to a tuple.\n",
        "  '''\n",
        "  icu_map = dict()\n",
        "  feature_dict = dict()\n",
        "  data = df.copy()\n",
        "  icu_id_list = data['ICUSTAY_ID'].unique()\n",
        "  for icu_id in icu_id_list:\n",
        "    data_temp = data[data['ICUSTAY_ID'] == icu_id]\n",
        "    temp_list = []\n",
        "    for f in feature_list:\n",
        "      x = np.array(data_temp[x_val]).reshape(-1, 1)\n",
        "      y = np.array(data_temp[f])\n",
        "      reg = LinearRegression().fit(x, y)\n",
        "      feature_dict[icu_id, f] = (reg.coef_.item(), reg.intercept_)\n",
        "\n",
        "  feature_df = pd.DataFrame.from_dict(feature_dict, orient='index').reset_index()\n",
        "  feature_df[['ICUSTAY_ID', 'FEATURE']]= pd.DataFrame(feature_df['index'].to_list())\n",
        "  feature_df = feature_df.rename(columns = {0:'RATE', 1:'BIAS'}).drop(columns = ['index'])\n",
        "\n",
        "  return feature_df\n",
        "    "
      ],
      "metadata": {
        "id": "tJPYLPr29wjw"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def diagnoses_map(col:any) -> str:\n",
        "  '''A mapping of ICD code to diagnosis.\n",
        "\n",
        "  Args: \n",
        "    col = the column to input, any value\n",
        "  Returns:\n",
        "    result = string corresponding to the ICD9 code\n",
        "  '''\n",
        "  if str(col).startswith(('E', 'V')):\n",
        "    result = 'DIAG_EXTERNAL'\n",
        "  elif math.isnan(float(col)):\n",
        "    result = 'NONE'\n",
        "  else:\n",
        "    val = int(col)\n",
        "\n",
        "    if val < 140:\n",
        "      result = 'DIAG_INFECTIOUS'\n",
        "    elif val < 240:\n",
        "      result = 'DIAG_NEOPLASMS'\n",
        "    elif val < 280:\n",
        "      result = 'DIAG_IMMUNITY'\n",
        "    elif val < 290:\n",
        "      result = 'DIAG_BLOOD'\n",
        "    elif val < 320:\n",
        "      result = 'DIAG_MENTAL'\n",
        "    elif val < 390:\n",
        "      result = 'DIAG_NERVOUS_SYS'\n",
        "    elif val < 460:\n",
        "      result = 'DIAG_CIRCULATORY_SYS'\n",
        "    elif val < 520:\n",
        "      result = 'DIAG_RESP_SYS'\n",
        "    elif val < 580:\n",
        "      result = 'DIAG_DIGESTIVE_SYS'\n",
        "    elif val < 630:\n",
        "      result = 'DIAG_GENITOURINARY'\n",
        "    elif val < 680:\n",
        "      result = 'DIAG_PREGNANCY'\n",
        "    elif val < 710:\n",
        "      result = 'DIAG_SKIN'\n",
        "    elif val < 740:\n",
        "      result = 'DIAG_MUSC'\n",
        "    elif val < 760:\n",
        "      result = 'DIAG_CONGENITAL'\n",
        "    elif val < 780:\n",
        "      result = 'DIAG_PERINATAL'\n",
        "    elif val < 800:\n",
        "      result = 'DIAG_ILL_DEFINED'\n",
        "    elif val < 1000:\n",
        "      result = 'DIAG_INJURY'\n",
        "    else:\n",
        "      result = 'OTHER'\n",
        "  return result"
      ],
      "metadata": {
        "id": "1Jg_p1GiM3E5"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_diag_dataset(diagnoses_icd: pd.DataFrame) -> pd.DataFrame:\n",
        "  '''This function takes in the diagnoses data and returns columns that can be\n",
        "  input into the model.\n",
        "\n",
        "  Params:\n",
        "    diagnoses_icd: the diagnosis dataframe\n",
        "  Returns:\n",
        "    df_diag: dignosis vals to columns\n",
        "  '''\n",
        "  diagnoses_icd['GROUP'] = diagnoses_icd[\"ICD9_CODE\"].map(diagnoses_map)\n",
        "  df_diag = diagnoses_icd[(diagnoses_icd['GROUP'] != 'OTHER') & (diagnoses_icd['GROUP'] != 'NONE')]\n",
        "  df_diag['value'] = 1\n",
        "  df_diag = df_diag.pivot_table(values = 'value', index = ['SUBJECT_ID', 'HADM_ID'], columns = 'GROUP').reset_index()\n",
        "  df_diag.fillna(0, inplace = True)\n",
        "  return df_diag"
      ],
      "metadata": {
        "id": "xL0DX44QRqhd"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Datasets"
      ],
      "metadata": {
        "id": "3UtoVpd11lrq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file = 'CHARTEVENTS_LITE.csv'\n",
        "chartevents = pd.read_csv(path+file)\n",
        "chartevents['CHARTTIME'] = pd.to_datetime(chartevents['CHARTTIME'])"
      ],
      "metadata": {
        "id": "ky0m7pdHIjLO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = 'ICUSTAYS_LITE.csv'\n",
        "icustays = pd.read_csv(path+file)\n",
        "icustays['OUTTIME'] = pd.to_datetime(icustays['OUTTIME'])"
      ],
      "metadata": {
        "id": "zpp_f9IhI10J"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = 'DIAGNOSES_ICD.csv'\n",
        "diagnoses_icd = pd.read_csv(path+file)"
      ],
      "metadata": {
        "id": "ksgG_zNuznuV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file = 'D_ICD_DIAGNOSES.csv'\n",
        "d_icd_diagnoses = pd.read_csv(path+file)"
      ],
      "metadata": {
        "id": "8HbGyWKdzzOO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Process Data"
      ],
      "metadata": {
        "id": "sI7xYNeyVTUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diagnosis = create_diag_dataset(diagnoses_icd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xV_giWIvVWaG",
        "outputId": "f6e9a343-54f3-48cd-b893-7af96bda05bd"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-79-eb8b718261b0>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_diag['value'] = 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chartevents_merged = chartevents.merge(icustays, on='ICUSTAY_ID', how='inner').dropna(subset=['ICUSTAY_ID'])"
      ],
      "metadata": {
        "id": "ojo9OfGTJbup"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_df=pd.DataFrame([])\n",
        "base_df['ICUSTAY_ID'] = icustays.ICUSTAY_ID\n",
        "base_df['HOUR'] = 1\n",
        "base_df_extended = pd.concat([pd.DataFrame({'ICUSTAY_ID': row.ICUSTAY_ID, 'HOUR': pd.RangeIndex(1,HOURS_LIMIT+1)}) for i, row in base_df.iterrows()], ignore_index=True)\n",
        "\n",
        "data_all = base_df_extended.copy()\n",
        "list_of_features = [{'ID':223761, 'DESC':'TEMP', 'CESTAT':True}, {'ID':220050, 'DESC':'BPRS_SYS', 'CESTAT':True}]\n",
        "for elem in list_of_features:\n",
        "  ID = elem['ID']\n",
        "  DESC = elem['DESC']\n",
        "  data = chartevents_merged.loc[chartevents_merged.ITEMID==ID]\n",
        "  data['HOUR'] = np.ceil((data['OUTTIME']-data['CHARTTIME'])/pd.Timedelta(1,'h'))\n",
        "  data['HOUR'] = data.HOUR.astype('int64')\n",
        "  data = data.loc[data.HOUR <= HOURS_LIMIT]#last 48 hours only\n",
        "  #SHOWS THAT MEASUREMENTS ARE NOT UNIFORMLY TAKEN (SO MISSING DATA EXPECTED)\n",
        "  #data.HOUR.plot.hist(bins=HOURS_LIMIT)\n",
        "  #WHEN CNT>1 SHOWS THAT MULTIPLE DATA POINTS EXISTS PER HOUR\n",
        "  #print(data.groupby(['ICUSTAY_ID', 'HOUR']).size().reset_index(name='CNT').sort_values(by='CNT').groupby(['ICUSTAY_ID']).last().reset_index().head(20))\n",
        "\n",
        "  #TODO AVERAGING WON'T WORK FOR CATEGORICAL DATA\n",
        "  data_avg = data.groupby(['ICUSTAY_ID', 'HOUR'])['VALUENUM'].mean().reset_index()\n",
        "  ALL_AVG = data_avg.VALUENUM.mean() #tobe used if no data exists for the icu stay\n",
        "  icustay_most_recent_data = data_avg.sort_values(by='HOUR').groupby('ICUSTAY_ID').first().reset_index()[['ICUSTAY_ID', 'VALUENUM']] \n",
        "  icustay_most_recent_data_map = defaultdict(lambda:np.NaN, dict(zip(icustay_most_recent_data.ICUSTAY_ID, icustay_most_recent_data.VALUENUM)))#tobe used for missing values i.e. use most recent measurement\n",
        "\n",
        "  #filling missing values\n",
        "  data_extended = base_df_extended.merge(data_avg, on=['ICUSTAY_ID', 'HOUR'], how='left')\n",
        "  data_extended['VALUENUM'] = data_extended.apply(lambda row: fill_missing_values(row['VALUENUM'], icustay_most_recent_data_map[row['ICUSTAY_ID']], ALL_AVG), axis=1)\n",
        "  data_all[DESC] = data_extended['VALUENUM'] #assuming order is maintained \n",
        "\n",
        "regress_ft_list = ['TEMP', 'BPRS_SYS']\n",
        "regressed_features = regress_features(data_all, 'HOUR', regress_ft_list)\n",
        "\n",
        "regression_df = pd.DataFrame()\n",
        "for ft in [feature['DESC'] for feature in list_of_features if feature['CESTAT']]:\n",
        "  data_temp = regressed_features[regressed_features['FEATURE'] == ft][['ICUSTAY_ID', 'RATE', 'BIAS']]\n",
        "  data_temp = data_temp.rename(columns = {'RATE': 'CESTAT_'+ft+'_RATE', 'BIAS': 'CESTAT_'+ft+'_BIAS'})#later will use CESTAT prefix when giving datasets to models\n",
        "  regression_df = data_temp if regression_df.empty else regression_df.merge(data_temp, on = ['ICUSTAY_ID'])\n",
        "  "
      ],
      "metadata": {
        "id": "CksqWCkzHMAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d060cbf9-06df-48a6-caa4-cfb3d02b944b"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-83-ed13c5b1ce14>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['HOUR'] = np.ceil((data['OUTTIME']-data['CHARTTIME'])/pd.Timedelta(1,'h'))\n",
            "<ipython-input-83-ed13c5b1ce14>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data['HOUR'] = data.HOUR.astype('int64')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_final = data_all.pivot(index='ICUSTAY_ID', columns=['HOUR']).reset_index()\n",
        "reordered_columns = [(desc,hour) for hour in range(1,1+HOURS_LIMIT) for desc in [feature['DESC'] for feature in list_of_features]]\n",
        "df_final = df_final.reindex([('ICUSTAY_ID', '')]+reordered_columns, axis=1)\n",
        "df_final.columns = [str(col[0])+str(col[1]) for col in df_final.columns.values] #converting tuples to string for better display as well as making ICUSTAY_ID column name simpler\n",
        "df_final = df_final.merge(regression_df, on='ICUSTAY_ID', how='inner')\n",
        "df_final = df_final.merge(icustays[['ICUSTAY_ID', 'POSITIVE']], on='ICUSTAY_ID', how='inner')\n",
        "#df_final.head(5)"
      ],
      "metadata": {
        "id": "p5kAlRgrQ-Kp"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=df_final.iloc[:,:-1]\n",
        "y=df_final.iloc[:,-1:]\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
        "X_test, X_validation, y_test, y_validation = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0, stratify=y_temp)\n"
      ],
      "metadata": {
        "id": "4M1h4i1rQkkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([X_train, y_train], axis=1).to_csv('./data/all/XY_train_LITE.csv', index=False)\n",
        "pd.concat([X_test, y_test], axis=1).to_csv('./data/all/XY_test_LITE.csv', index=False)\n",
        "pd.concat([X_validation, y_validation], axis=1).to_csv('./data/all/XY_validation_LITE.csv', index=False)"
      ],
      "metadata": {
        "id": "e1Ex2bkgvFgd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}